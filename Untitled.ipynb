{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def load_weights(model, weights, debug = False, metrics = None, finetune=True):\n",
    "    if weights is None:\n",
    "        raise Exception(\"Weights not found.\")\n",
    "    \n",
    "    origModelWeights = deepcopy(model.get_weights())\n",
    "    weight_idx = 0\n",
    "    setWeights = True\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if \"batch\" in layer.name:\n",
    "            if debug: print(layer.name)\n",
    "        if layer.get_weights() != []:\n",
    "            if layer.get_weights()[0].shape == weights[weight_idx].shape and i < len(model.layers)-1:\n",
    "                temp = []\n",
    "                for j, weight in enumerate(layer.get_weights()):\n",
    "                    if weight_idx+j < len(weights)-1:\n",
    "                        weight_idx += j\n",
    "                        temp.append(weights[weight_idx])\n",
    "                    else:\n",
    "                        setWeights = False\n",
    "                if setWeights:\n",
    "                    layer.set_weights(temp)\n",
    "                    if finetune: layer.trainable = False\n",
    "                    weight_idx += 1\n",
    "                if debug: print(\"Weight group {} of {} used\".format(weight_idx, len(weights)))\n",
    "                if debug: print(layer.name, \"Weight Changed\")\n",
    "        else:\n",
    "            if debug: print(layer.name, \"Weight Not Changed\")\n",
    "            \n",
    "    if debug: \n",
    "        for weight in weights[weight_idx-1:]:\n",
    "            print(weight.shape)\n",
    "    \n",
    "    assert (origModelWeights[0] != model.get_weights()[0]).any()\n",
    "    \n",
    "    return model\n",
    "\n",
    "from keras.optimizers import Nadam\n",
    "from clr_callback import CyclicLR\n",
    "\n",
    "def fit(model, ds, loss=\"categorical_crossentropy\", metrics=[\"acc\"], epochs=3, finetune=False, verbose=1):\n",
    "    optim = Nadam()\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    clr = CyclicLR(base_lr=base_lr, max_lr=max_lr,\n",
    "                   step_size=2000., mode='triangular')\n",
    "    \n",
    "    model.compile(optimizer=optim,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    if finetune:\n",
    "        orig_epochs = epochs\n",
    "        epochs //= 2\n",
    "        model.fit_generator(generator=ds.train_gen, steps_per_epoch=ds.train_steps,\n",
    "            epochs=epochs, verbose=verbose, callbacks=[clr], validation_data=ds.val_gen,\n",
    "            validation_steps=ds.val_steps)\n",
    "        \n",
    "        base_lr /= 2\n",
    "        max_lr /= 2\n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "            \n",
    "        model.compile(optimizer=optim,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "        \n",
    "        model.fit_generator(generator=ds.train_gen, steps_per_epoch=ds.train_steps,\n",
    "            epochs=epochs, verbose=verbose, callbacks=[clr], validation_data=ds.val_gen,\n",
    "            validation_steps=ds.val_steps)\n",
    "        \n",
    "        epochs = orig_epochs\n",
    "    \n",
    "    return model.fit_generator(generator=ds.train_gen, steps_per_epoch=ds.train_steps,\n",
    "                        epochs=epochs, verbose=verbose, callbacks=[clr], validation_data=ds.val_gen,\n",
    "                        validation_steps=ds.val_steps).history['val_loss'][-1]\n",
    "    \n",
    "\n",
    "def twosFloor(num):\n",
    "    if num % 2 == 1:\n",
    "        return (num - 1) // 2\n",
    "    else:\n",
    "        return num // 2\n",
    "\n",
    "def shiftedTwosFloor(num):\n",
    "    num += 3\n",
    "    if num % 2 == 1:\n",
    "        return (num - 1) // 2\n",
    "    else:\n",
    "        return num // 2\n",
    "\n",
    "from model_assembly import assemble_model\n",
    "import numpy as np\n",
    "from dataset import Dataset\n",
    "from IPython.core.debugger import set_trace\n",
    "ds = Dataset()\n",
    "\n",
    "def convert_to_matrix(state, new_rep):\n",
    "    M = []\n",
    "    for _ in range(state.max_depth):\n",
    "        M.append([])\n",
    "        for _ in range(state.max_depth):\n",
    "            M[-1].append(\"\")\n",
    "    for i in range(state.size):\n",
    "        M[twosFloor(i)][shiftedTwosFloor(i)] = new_rep[i]\n",
    "        \n",
    "    return M\n",
    "\n",
    "import pickle as p\n",
    "import database as db\n",
    "\n",
    "def eval_arch(state, node):\n",
    "    board = state.board\n",
    "    layer_types = state.layer_types\n",
    "    new_rep = []\n",
    "    for i in range(len(board)):\n",
    "        new_rep.append(layer_types[board[i]])\n",
    "    M = convert_to_matrix(state, new_rep)\n",
    "    \n",
    "    print(M)\n",
    "    try:\n",
    "        model = assemble_model(M)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return -1\n",
    "    prev_loss = 0 \n",
    "    results = db.select(\"\"\"SELECT loss FROM data WHERE depth={}\"\"\".format(node[\"depth\"]))\n",
    "    for res in results:\n",
    "        prev_loss += res\n",
    "    if prev_loss == 0:\n",
    "        prev_loss = None\n",
    "            \n",
    "    loss = fit(model, ds, finetune=False, verbose=1)\n",
    "        \n",
    "    if loss is not None and (prev_loss is None or loss < prev_loss):\n",
    "        db.insert(\"\"\"INSERT INTO data VALUES (?, ?, ?)\"\"\", (node[\"depth\"], loss, ''))\n",
    "        print(\"prev_loss: {}, new_loss: {}\".format(prev_loss, loss))\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.select(\"\"\"SELECT * FROM data\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 2.6827001912253245, ''), (6, 2.80123165675572, '')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = [['', 'conv2d3x3', 'conv2d3x3', '', '', '', '', '', '', ''], ['', '', 'conv2d3x3', '', '', '', '', '', '', ''], ['', '', '', 'conv2d1x1stride', 'conv2d3x3', '', '', '', '', ''], ['', '', '', '', 'conv2d1x1', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-3-f7fc2a9465eb>\u001b[0m(44)\u001b[0;36mzero_pad_layers\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     42 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 44 \u001b[0;31m    \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     46 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> layers\n",
      "[<tf.Tensor 'activation_32/Relu:0' shape=(?, 16, 16, 32) dtype=float32>, <tf.Tensor 'activation_33/Relu:0' shape=(?, 16, 16, 32) dtype=float32>]\n",
      "ipdb> c\n",
      "> \u001b[0;32m<ipython-input-3-f7fc2a9465eb>\u001b[0m(44)\u001b[0;36mzero_pad_layers\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     42 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 44 \u001b[0;31m    \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     46 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> layers\n",
      "[<tf.Tensor 'activation_35/Relu:0' shape=(?, 16, 16, 32) dtype=float32>, <tf.Tensor 'zero_padding2d_4/Pad:0' shape=(?, 16, 16, 32) dtype=float32>]\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "model = assemble_model(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 16, 16, 32)    128         input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 16, 16, 32)    128         conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 16, 16, 32)    0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 16, 16, 32)    1056        activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 16, 16, 32)    128         conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 16, 16, 32)    0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, 16, 16, 64)    0           activation_32[0][0]              \n",
      "                                                                   activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 16, 16, 32)    2080        concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 16, 16, 32)    128         conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 16, 16, 32)    0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 8, 8, 32)      9248        activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 8, 8, 32)      128         conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 8, 8, 32)      0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D) (None, 16, 16, 32)    0           activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)     (None, 16, 16, 64)    0           activation_35[0][0]              \n",
      "                                                                   zero_padding2d_4[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 16384)         0           concatenate_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 128)           2097280     flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 128)           512         dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 128)           0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 128)           0           activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 128)           16512       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 128)           512         dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 128)           0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 128)           0           activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 10)            1290        dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 2,129,130\n",
      "Trainable params: 2,128,362\n",
      "Non-trainable params: 768\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_tr, y_tr), (X_t, y_t) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 3008/50000 [>.............................] - ETA: 117s - loss: 2.0071 - acc: 0.2995"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f4bcfa5f5eac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_tr = to_categorical(y_tr)\n",
    "model.fit(X_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
