{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T14:06:17.600416Z",
     "start_time": "2018-01-15T14:05:52.759622Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import (Conv1D, LSTM, BatchNormalization, Flatten, Dense, Activation, \n",
    "                          Input, concatenate)\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.optimizers import Nadam\n",
    "from clr_callback import CyclicLR\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T14:06:17.713298Z",
     "start_time": "2018-01-15T14:06:17.603349Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_layer(prev):\n",
    "    x = Conv1D(32, 1, kernel_regularizer=l2(10e-4),\n",
    "               bias_regularizer=l2(10e-4))(prev)\n",
    "    x = BatchNormalization(x)\n",
    "    x = concatenate([x, prev], axis=-1)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def res_layer(prev):\n",
    "    x = Conv1D(32, 1, kernel_regularizer=l2(10e-4),\n",
    "               bias_regularizer=l2(10e-4))(prev)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv1D(32, 1, kernel_regularizer=l2(\n",
    "        10e-4), bias_regularizer=l2(10e-4))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = concatenate([x, prev], axis=-1)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def lstm_layer(prev):\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(\n",
    "        10e-4), bias_regularizer=l2(10e-4)))(prev)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(\n",
    "        10e-4), bias_regularizer=l2(10e-4)))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def lstm_value_head(prev):\n",
    "    x = Bidirectional(LSTM(1, return_sequences=False, kernel_regularizer=l2(\n",
    "        10e-4), bias_regularizer=l2(10e-4)))(prev)\n",
    "    x = Dense(32)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(1, activation=\"tanh\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def lstm_policy_head(prev, output_length):\n",
    "    x = Bidirectional(LSTM(1, return_sequences=True, kernel_regularizer=l2(\n",
    "        10e-4), bias_regularizer=l2(10e-4)))(prev)\n",
    "    x = Bidirectional(LSTM(1, return_sequences=False, kernel_regularizer=l2(\n",
    "        10e-4), bias_regularizer=l2(10e-4)))(x)\n",
    "    x = Dense(output_length, activation=\"softmax\",\n",
    "              kernel_regularizer=l2(10e-4), bias_regularizer=l2(10e-4))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T14:06:17.817100Z",
     "start_time": "2018-01-15T14:06:17.716113Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Nadam\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.initializers import glorot_uniform, zero\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def create_net(time_steps, input_length, output_length, num_layers=8):\n",
    "    inp = Input(shape=(time_steps, input_length))\n",
    "    x = inp\n",
    "    for _ in range(num_layers):\n",
    "        x = lstm_layer(x)\n",
    "    policy = lstm_policy_head(x, output_length)\n",
    "    value = lstm_value_head(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=[policy, value])\n",
    "    \n",
    "    model.compile(optimizer=Nadam(), loss = [\"categorical_crossentropy\", \"mse\"], loss_weights = [.5, .5], \n",
    "                  metrics=None)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
